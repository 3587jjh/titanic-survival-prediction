{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Cost: 0.4691 || Valid Cost: nan\n",
      "Train Cost: 0.4491 || Valid Cost: nan\n",
      "Train Cost: 0.4438 || Valid Cost: nan\n",
      "Train Cost: 0.4420 || Valid Cost: nan\n",
      "Train Cost: 0.4413 || Valid Cost: nan\n",
      "----------------------------------------\n",
      "Fin\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "##########################################################\n",
    "def process_data(_df):\n",
    "    df = _df.copy()\n",
    "    if len(df) == 0:\n",
    "        return df\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "    df.drop(['SibSp', 'Parch', 'Cabin', 'Ticket', 'Name'], axis=1, inplace=True)\n",
    "    # fill missing values for ['Embarked', 'Fare', 'Age']\n",
    "    freq_port = df['Embarked'].mode()[0]\n",
    "    df['Embarked'].fillna(freq_port, inplace=True)\n",
    "    fare_med = df['Fare'].median()\n",
    "    df['Fare'].fillna(fare_med, inplace=True)\n",
    "    \n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1}).astype(int)\n",
    "    df['Embarked'] = df['Embarked'].map({'C':0, 'Q':1, 'S':2}).astype(int)\n",
    "    \n",
    "    guess_age = np.zeros(4)\n",
    "    for i in range(4):\n",
    "        guess_age[i] = df[df['Pclass']==i]['Age'].mean()\n",
    "    for i in range(4):\n",
    "        df.loc[df['Age'].isnull() & (df['Pclass']==i), 'Age'] = guess_age[i]\n",
    "\n",
    "    df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "    return df\n",
    "\n",
    "##########################################################\n",
    "def normalize(_df1, _df2):\n",
    "    df1 = _df1.copy()\n",
    "    df2 = _df2.copy()\n",
    "    for col in ['Pclass', 'Age', 'Fare', 'FamilySize']:\n",
    "        mean = df1[col].mean()\n",
    "        std = df1[col].std()\n",
    "        df1[col] = (df1[col] - mean) / std\n",
    "        if len(df2) > 0:\n",
    "            df2[col] = (df2[col] - mean) / std\n",
    "    return df1,df2\n",
    "\n",
    "##########################################################\n",
    "def df_to_tensor(_df1, _df2):\n",
    "    df1 = process_data(_df1)\n",
    "    df2 = process_data(_df2)\n",
    "    df1, df2 = normalize(df1, df2)\n",
    "    x1 = torch.FloatTensor(df1.drop(['PassengerId','Survived'], axis=1).values)\n",
    "    y1 = torch.FloatTensor(df1[['Survived']].values)\n",
    "    x2 = torch.FloatTensor()\n",
    "    y2 = torch.FloatTensor()\n",
    "    if len(df2) > 0:\n",
    "        x2 = torch.FloatTensor(df2.drop(['PassengerId','Survived'], axis=1).values)\n",
    "        y2 = torch.FloatTensor(df2[['Survived']].values)\n",
    "    return x1,y1,x2,y2\n",
    "\n",
    "##########################################################\n",
    "def evaluate(x, y, W, b):\n",
    "    if len(x)==0 or len(x)!=len(y):\n",
    "        return np.nan\n",
    "    pred = torch.sigmoid(x.matmul(W)+b)\n",
    "    cost = F.binary_cross_entropy(pred, y)\n",
    "    return cost.item()\n",
    "\n",
    "##########################################################\n",
    "def logistic_regression(x_train, y_train, x_valid, y_valid, lr, wd):\n",
    "    global epochs, log_freq\n",
    "    # requires_grad를 True로 설정하면 역전파중에 해당 Tensor의 변화도를 추가로 계산함\n",
    "    W = torch.zeros((x_train.shape[1],1), requires_grad=True)\n",
    "    b = torch.zeros(1, requires_grad=True)\n",
    "    optimizer = optim.SGD([W,b], lr=lr, weight_decay=wd)\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        pred = torch.sigmoid(x_train.matmul(W)+b)\n",
    "        cost = F.binary_cross_entropy(pred, y_train)\n",
    "        # pytorch는 미분을 통해 얻은 기울기를 이전에 계산된 기울기 값에 누적시키는 특징이 있음\n",
    "        # 새로운 기울기를 계산하기 위해 기존 기울기를 0으로 초기화 해야함\n",
    "        optimizer.zero_grad()\n",
    "        # autograd를 사용하여 역전파를 수행한다. requires_grad=True인 모든 tensor에 대해 \n",
    "        # 손실의 변화도를 계산하여 각 tensor의 .grad에 저장\n",
    "        cost.backward()\n",
    "        # 각 tensor의 .grad값을 이용해 tensor를 업데이트함\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch%(epochs//log_freq) == 0:\n",
    "            cost_valid = evaluate(x_valid, y_valid, W, b)\n",
    "            print('Train Cost: {:.4f} || Valid Cost: {:.4f}'\\\n",
    "                .format(cost.item(), cost_valid))\n",
    "                \n",
    "    print('-'*40)        \n",
    "    cost_valid = evaluate(x_valid, y_valid, W, b)        \n",
    "    return W,b,cost_valid\n",
    "    \n",
    "##########################################################\n",
    "def kfold_cv(df, lr, wd, k=7):\n",
    "    fold = df.shape[0]//k\n",
    "    cv_error = 0.0\n",
    "    for i in range(k):\n",
    "        df_train = df.drop(df.index[i*fold:(i+1)*fold])\n",
    "        df_valid = df[:][i*fold:(i+1)*fold]\n",
    "        x_train, y_train, x_valid, y_valid = df_to_tensor(df_train, df_valid)\n",
    "        W,b,error = logistic_regression(x_train, y_train, x_valid, y_valid, lr, wd)\n",
    "        cv_error += error\n",
    "    cv_error /= k\n",
    "    return cv_error\n",
    "\n",
    "##########################################################\n",
    "df_train = pd.read_csv('train.csv').sample(frac=1) # shuffle\n",
    "lr = 0.02\n",
    "wd = 0.002\n",
    "epochs = 6000\n",
    "log_freq = 5\n",
    "\n",
    "#cv_error = kfold_cv(df_train, lr, wd)\n",
    "#print('cv_error: {:4f}'.format(cv_error))\n",
    "#sys.exit(0)\n",
    "\n",
    "#############################\n",
    "df_valid = pd.DataFrame()\n",
    "x_train, y_train, x_valid, y_valid = df_to_tensor(df_train, df_valid)\n",
    "W,b,error = logistic_regression(x_train, y_train, x_valid, y_valid, lr, wd)\n",
    "\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_test['Survived'] = np.nan\n",
    "x_train, y_train, x_test, y_test = df_to_tensor(df_train, df_test)\n",
    "\n",
    "pred = torch.sigmoid(x_test.matmul(W)+b).detach().numpy()\n",
    "output = pd.DataFrame({'PassengerId': df_test['PassengerId']})\n",
    "output['Survived'] = 0\n",
    "for idx, row in output.iterrows():\n",
    "    output.loc[idx, 'Survived'] = 1 if pred[idx][0]>0.5 else 0\n",
    "    \n",
    "output.to_csv('submission.csv', index=False)\n",
    "print('Fin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
